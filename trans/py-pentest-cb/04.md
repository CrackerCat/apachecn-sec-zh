# 四、Python 数据解析

在本章中，我们将介绍以下配方：

*   解析 HTML 表
*   从 HTML 文档中提取数据
*   解析 XML 数据

# 介绍

由于我们已经下载了前面配方中的网页，现在我们可以讨论如何处理这些文件并解析它们以获得所需信息。

# 解析 HTML 表

从服务器下载 HTML 页面后，我们必须从中提取所需的数据。Python 中有许多模块可以帮助实现这一点。这里我们可以使用 Python 包`BeautifulSoup`。

# 准备

像往常一样，确保安装了所有必需的软件包。对于这个脚本，我们需要`BeautifulSoup`和`pandas`。您可以使用`pip`进行安装：

```
pip install bs4 
pip install pandas  
```

`pandas`是 Python 中的一个开源数据分析库。

# 怎么做。。。

我们可以从下载的页面解析 HTML 表，如下所示：

1.  像往常一样，我们必须为脚本导入所需的模块。这里，我们导入`BeautifulSoup`用于解析 HTML，导入`pandas`用于处理解析的数据。此外，我们还需要导入从服务器获取网页的`urllib`模块：

```
import urllib2 
import pandas as pd 
from bs4 import BeautifulSoup 
```

2.  现在我们可以从服务器获取 HTML 页面；为此，我们可以使用`urllib`模块：

```
url = "https://www.w3schools.com/html/html_tables.asp" 
try: 
    page = urllib2.urlopen(url) 
except Exception as e: 
    print e 
    pass 
```

3.  然后，我们可以使用`BeautifulSoup`解析 HTML 并从中获取`table`：

```
soup = BeautifulSoup(page, "html.parser") 
table = soup.find_all('table')[0] 
```

在这里，它将获得网页上的第一个表。

4.  现在我们可以使用`pandas`库为表创建`DataFrame`：

```
new_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7)) 
```

这将创建一个包含三列六行的`DataFrame`。这些列将显示公司名称、联系人详细信息和国家/地区。

5.  现在我们必须解析数据并将其添加到`DataFrame:`

```
row_number = 0 
for row in table.find_all('tr'): 
    column_number = 0 
    columns = row.find_all('td') 
    for column in columns: 
        new_table.iat[row_number, columns_number] = column.get_text() 
        columns_number += 1 
    row_number += 1  
print new_table 
```

这将打印`DataFrame`。

`DataFrame` is a two-dimensional, labeled data structure with columns of potentially different types. It is more like a `dict` of series objects.

6.  此脚本可以使用 Python 3 运行，但需要做一些更改，如下所示：

```
import urllib.request 
import pandas as pd 
from bs4 import BeautifulSoup  
url = "https://www.w3schools.com/html/html_tables.asp" 
try: 
    page = urllib.request.urlopen(url) 
except Exception as e: 
    print(e) 
    pass 
soup = BeautifulSoup(page, "html.parser")  
table = soup.find_all('table')[0]  
new_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7))  
row_number = 0 
for row in table.find_all('tr'): 
    column_number = 0 
    columns = row.find_all('td') 
    for column in columns: 
        new_table.iat[row_number, column_number] = column.get_text() 
        column_number += 1 
    row_number += 1  
print(new_table) 
```

对`urllib`模块和`print`语句进行了主要更改。

您可以在[了解更多关于`pandas`数据分析工具包的信息 https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/) 。

# 从 HTML 文档中提取数据

在`pandas`库的帮助下，我们可以将解析后的数据提取为.csv 或 Excel 格式。

# 准备

要使用`pandas`模块中导出解析数据到 Excel 的功能，我们需要另一个依赖模块`openpyxl`，因此请确保您安装了带有`pip`的`openpyxl`：

```
pip install openpyxl  
```

# 怎么做。。。

我们可以将数据从 HTML 提取到.csv 或 Excel 文档，如下所示：

1.  要创建.csv 文件，我们可以使用`pandas`中的`to_csv()`方法。我们可以将前面的配方改写如下：

```
import urllib.request 
import pandas as pd 
from bs4 import BeautifulSoup  
url = "https://www.w3schools.com/html/html_tables.asp" 
try: 
    page = urllib.request.urlopen(url) 
except Exception as e: 
    print(e) 
    pass 
soup = BeautifulSoup(page, "html.parser")  
table = soup.find_all('table')[0]  
new_table = pd.DataFrame(columns=['Company', 'Contact', 'Country'], index=range(0, 7))  
row_number = 0 
for row in table.find_all('tr'): 
    column_number = 0 
    columns = row.find_all('td') 
    for column in columns: 
        new_table.iat[row_number, column_number] = column.get_text() 
        column_number += 1 
    row_number += 1  
new_table.to_csv('table.csv') 
```

这将创建一个名为`table.csv`的.csv 文件。

2.  同样，我们可以使用`to_excel()`方法导出到 Excel。

将上一个脚本中的最后一行更改为以下内容：

```
new_table.to_excel('table.xlsx') 
```

# 解析 XML 数据

有时，我们会从服务器得到一个 XML 响应，我们必须解析 XML 来提取数据。我们可以使用`xml.etree.ElementTree`模块解析 XML 文件。

# 准备

我们必须安装所需的模块`xml`：

```
pip install xml  
```

# 怎么做。。。

下面是我们如何使用 XML 模块解析 XML 数据：

1.  首先导入所需的模块。由于此脚本在 Python 3 中，请确保导入了正确的模块：

```
from urllib.request import urlopen 
from xml.etree.ElementTree import parse 
```

2.  现在使用`urllib`模块中的`urlopen`方法获取 XML 文件：

```
url = urlopen('http://feeds.feedburner.com/TechCrunch/Google') 
```

3.  现在使用`xml.etree.ElementTree`模块中的`parse`方法解析 XML 文件：

```
xmldoc = parse(url) 
```

4.  现在迭代并以 XML 打印详细信息：

```
for item in xmldoc.iterfind('channel/item'): 
    title = item.findtext('title') 
    desc = item.findtext('description') 
    date = item.findtext('pubDate') 
    link = item.findtext('link')  
    print(title) 
    print(desc) 
    print(date) 
    print(link) 
    print('---------') 
```

5.  此脚本可以重写为在 Python 2 中运行，如下所示：

```
from urllib2 import urlopen 
from xml.etree.ElementTree import parse  
url = urlopen('http://feeds.feedburner.com/TechCrunch/Google') 
xmldoc = parse(url) 
xmldoc.write('output.xml') 
for item in xmldoc.iterfind('channel/item'): 
   title = item.findtext('title') 
   desc = item.findtext('description') 
   date = item.findtext('pubDate') 
   link = item.findtext('link')  
    print title 
    print desc 
    print date 
    print link 
    print '---------' 
```

这也可以导出到 Excel 或.csv，就像我们在前面的配方中所做的那样。